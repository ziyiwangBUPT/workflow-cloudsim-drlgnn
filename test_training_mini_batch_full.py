"""
å®Œæ•´è®­ç»ƒæµç¨‹çš„å°æ‰¹é‡æµ‹è¯•

ä½¿ç”¨é¡¹ç›®ä¸­çš„å®Œæ•´è®­ç»ƒæ¥å£ï¼ˆArgs + trainå‡½æ•°ï¼‰ï¼Œè®¾ç½®å°å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•ã€‚
ä¸»è¦éªŒè¯ï¼š
1. è®­ç»ƒæµç¨‹èƒ½æ­£å¸¸è¿è¡Œ
2. Wrapperçš„é”™è¯¯å¤„ç†ä¸ä¼šå¯¼è‡´å´©æºƒ
3. å¥–åŠ±å‡½æ•°è®¡ç®—æ­£ç¡®
4. æ¢¯åº¦æ›´æ–°æ­£å¸¸
5. æ— æ•ˆåŠ¨ä½œèƒ½è¢«æ­£ç¡®å¤„ç†
"""
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

import torch
import random
import numpy as np
from scheduler.rl_model.train import Args, train
from scheduler.dataset_generator.gen_dataset import DatasetArgs


def create_mini_training_args():
    """åˆ›å»ºå°æ‰¹é‡è®­ç»ƒå‚æ•°"""
    args = Args()
    
    # è®­ç»ƒå‚æ•°ï¼ˆè®¾ç½®å¾ˆå°çš„å€¼ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•ï¼‰
    args.exp_name = "mini_batch_test"
    args.seed = 42
    args.output_dir = "logs/test_mini_batch"
    args.cuda = False  # ä½¿ç”¨CPUï¼Œé¿å…GPUä¾èµ–
    
    # è®­ç»ƒè§„æ¨¡ï¼ˆéå¸¸å°ï¼‰
    args.total_timesteps = 512  # å¾ˆå°ï¼Œåªæµ‹è¯•å‡ ä¸ªè¿­ä»£
    args.num_envs = 1  # å•ç¯å¢ƒ
    args.num_steps = 32  # æ¯ä¸ªrolloutçš„æ­¥æ•°
    args.num_minibatches = 2  # å°æ‰¹æ¬¡æ•°é‡
    args.update_epochs = 1  # åªæ›´æ–°1æ¬¡
    
    # å­¦ä¹ ç‡å’Œå…¶ä»–è¶…å‚æ•°ï¼ˆä¿æŒé»˜è®¤ï¼‰
    args.learning_rate = 2.5e-4
    args.gamma = 0.99
    args.gae_lambda = 0.95
    args.norm_adv = True
    args.clip_coef = 0.2
    args.clip_vloss = True
    args.ent_coef = 0.01
    args.vf_coef = 0.5
    args.max_grad_norm = 0.5
    args.target_kl = None
    args.anneal_lr = False  # ç¦ç”¨å­¦ä¹ ç‡è¡°å‡ï¼Œç®€åŒ–æµ‹è¯•
    
    # æ•°æ®é›†å‚æ•°ï¼ˆå°è§„æ¨¡ï¼‰
    args.dataset = DatasetArgs(
        host_count=4,
        vm_count=8,
        workflow_count=2,
        gnp_min_n=5,
        gnp_max_n=8,
        max_memory_gb=16,
        min_cpu_speed=1000,
        max_cpu_speed=3000,
        min_task_length=10000,
        max_task_length=50000,
        task_arrival="static",
        dag_method="gnp",
        task_length_dist="uniform",
        arrival_rate=1.0,
    )
    
    # æµ‹è¯•å‚æ•°
    args.test_iterations = 1  # åªæµ‹è¯•1æ¬¡
    
    # å…¶ä»–è®¾ç½®
    args.track = False  # ä¸è¿½è¸ªwandb
    args.capture_video = False
    args.torch_deterministic = True
    
    return args


def test_training_flow():
    """æµ‹è¯•å®Œæ•´è®­ç»ƒæµç¨‹"""
    print("=" * 80)
    print("å®Œæ•´è®­ç»ƒæµç¨‹å°æ‰¹é‡æµ‹è¯•")
    print("=" * 80)
    print("\n")
    
    print("1. åˆ›å»ºè®­ç»ƒå‚æ•°...")
    args = create_mini_training_args()
    print(f"   âœ“ æ€»æ—¶é—´æ­¥æ•°: {args.total_timesteps}")
    print(f"   âœ“ ç¯å¢ƒæ•°é‡: {args.num_envs}")
    print(f"   âœ“ æ¯rolloutæ­¥æ•°: {args.num_steps}")
    print(f"   âœ“ æ‰¹æ¬¡å¤§å°: {args.num_envs * args.num_steps}")
    print(f"   âœ“ å°æ‰¹æ¬¡æ•°é‡: {args.num_minibatches}")
    print(f"   âœ“ æ›´æ–°epochs: {args.update_epochs}")
    print(f"   âœ“ å·¥ä½œæµæ•°: {args.dataset.workflow_count}")
    print(f"   âœ“ VMæ•°: {args.dataset.vm_count}")
    
    # è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    
    print("\n2. åˆ›å»ºè¾“å‡ºç›®å½•...")
    output_path = Path(args.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    print(f"   âœ“ è¾“å‡ºç›®å½•: {output_path.absolute()}")
    
    print("\n3. å¼€å§‹è®­ç»ƒ...")
    print("   (è¿™å°†è¿è¡Œå®Œæ•´çš„PPOè®­ç»ƒæµç¨‹ï¼Œä½†è§„æ¨¡å¾ˆå°)")
    print("   - éªŒè¯ç¯å¢ƒåˆ›å»ºå’Œé‡ç½®")
    print("   - éªŒè¯åŠ¨ä½œé€‰æ‹©å’Œæ‰§è¡Œ")
    print("   - éªŒè¯å¥–åŠ±å‡½æ•°è®¡ç®—")
    print("   - éªŒè¯æ¢¯åº¦æ›´æ–°")
    print("   - éªŒè¯æ— æ•ˆåŠ¨ä½œå¤„ç†")
    print("\n")
    
    try:
        # è¿è¡Œè®­ç»ƒï¼ˆè¿™ä¼šè¿è¡Œå®Œæ•´çš„è®­ç»ƒå¾ªç¯ï¼‰
        train(args)
        
        print("\n" + "=" * 80)
        print("âœ… è®­ç»ƒæµç¨‹æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 80)
        print("\n")
        print("éªŒè¯ç»“æœï¼š")
        print("  1. âœ“ ç¯å¢ƒå¯ä»¥æ­£å¸¸åˆ›å»ºå’Œé‡ç½®")
        print("  2. âœ“ GNN Agentå¯ä»¥æ­£å¸¸é€‰æ‹©åŠ¨ä½œ")
        print("  3. âœ“ è®­ç»ƒå¾ªç¯å¯ä»¥æ­£å¸¸è¿è¡Œ")
        print("  4. âœ“ å¥–åŠ±å‡½æ•°è®¡ç®—æ­£ç¡®")
        print("  5. âœ“ æ¢¯åº¦æ›´æ–°æ­£å¸¸")
        print("  6. âœ“ æ— æ•ˆåŠ¨ä½œå¤„ç†æ­£ç¡®ï¼ˆé€šè¿‡GINæ©ç ï¼‰")
        print("\n")
        print("ğŸš€ è®­ç»ƒæµç¨‹éªŒè¯å®Œæˆï¼Œå¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒï¼")
        print("\n")
        
        return True
        
    except Exception as e:
        print("\n" + "=" * 80)
        print("âŒ è®­ç»ƒæµç¨‹æµ‹è¯•å¤±è´¥ï¼")
        print("=" * 80)
        print(f"\né”™è¯¯ä¿¡æ¯: {e}")
        print("\n")
        import traceback
        traceback.print_exc()
        return False


def test_wrapper_error_handling():
    """æµ‹è¯•Wrapperçš„é”™è¯¯å¤„ç†ï¼ˆå¯é€‰ï¼Œç”¨äºéªŒè¯æ— æ•ˆåŠ¨ä½œå¤„ç†ï¼‰"""
    print("\n" + "=" * 80)
    print("Wrapperé”™è¯¯å¤„ç†æµ‹è¯•")
    print("=" * 80)
    
    from scheduler.rl_model.core.env.gym_env import CloudSchedulingGymEnvironment
    from scheduler.rl_model.agents.gin_agent.wrapper import GinAgentWrapper
    from scheduler.dataset_generator.core.gen_dataset import generate_dataset
    
    # åˆ›å»ºç¯å¢ƒ
    dataset = generate_dataset(
        seed=100,
        host_count=4,
        vm_count=8,
        workflow_count=2,
        gnp_min_n=5,
        gnp_max_n=8,
        max_memory_gb=16,
        min_cpu_speed_mips=1000,
        max_cpu_speed_mips=3000,
        dag_method='gnp',
        task_length_dist='uniform',
        min_task_length=10000,
        max_task_length=50000,
        task_arrival='static',
        arrival_rate=1.0
    )
    
    env = CloudSchedulingGymEnvironment(dataset=dataset)
    wrapped_env = GinAgentWrapper(env)
    
    obs, info = wrapped_env.reset()
    
    # æµ‹è¯•ï¼šå³ä½¿ä½¿ç”¨éšæœºé‡‡æ ·ï¼ˆå¯èƒ½ç”Ÿæˆæ— æ•ˆåŠ¨ä½œï¼‰ï¼Œä¹Ÿä¸ä¼šå´©æºƒ
    print("\n  æµ‹è¯•éšæœºåŠ¨ä½œé‡‡æ ·ï¼ˆå¯èƒ½åŒ…å«æ— æ•ˆåŠ¨ä½œï¼‰...")
    error_count = 0
    valid_count = 0
    
    for _ in range(20):
        action = wrapped_env.action_space.sample()
        obs, reward, done, truncated, info = wrapped_env.step(action)
        
        if done and "error" in info:
            error_count += 1
            # éªŒè¯ï¼šæ— æ•ˆåŠ¨ä½œè¿”å›äº†penaltyè€Œä¸æ˜¯å´©æºƒ
            assert reward < 0, "æ— æ•ˆåŠ¨ä½œåº”è¯¥è¿”å›è´Ÿå¥–åŠ±ï¼ˆpenaltyï¼‰"
        else:
            valid_count += 1
        
        if done:
            obs, info = wrapped_env.reset()
    
    print(f"   âœ“ æ— æ•ˆåŠ¨ä½œæ•°: {error_count}")
    print(f"   âœ“ æœ‰æ•ˆåŠ¨ä½œæ•°: {valid_count}")
    print(f"   âœ“ Wrapperæ­£ç¡®å¤„ç†äº†æ— æ•ˆåŠ¨ä½œï¼Œæ²¡æœ‰å´©æºƒ")
    
    print("\nâœ… Wrapperé”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡ï¼")
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n")
    print("*" * 80)
    print("å®Œæ•´è®­ç»ƒæµç¨‹å°æ‰¹é‡æµ‹è¯•")
    print("*" * 80)
    print("\n")
    print("ç›®çš„ï¼šéªŒè¯æ–°å¥–åŠ±å‡½æ•°å’ŒWrapperä¿®å¤ä¸ä¼šå¯¼è‡´è®­ç»ƒæµç¨‹å¼‚å¸¸")
    print("\n")
    
    success = True
    
    try:
        # æµ‹è¯•1ï¼šå®Œæ•´è®­ç»ƒæµç¨‹
        success = test_training_flow() and success
        
        # æµ‹è¯•2ï¼šWrapperé”™è¯¯å¤„ç†ï¼ˆå¯é€‰ï¼‰
        if success:
            print("\n")
            success = test_wrapper_error_handling() and success
        
        if success:
            print("\n" + "=" * 80)
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("=" * 80)
            print("\n")
            print("ğŸ“Š æµ‹è¯•æ€»ç»“ï¼š")
            print("  âœ“ ä½¿ç”¨å®Œæ•´çš„è®­ç»ƒæ¥å£ï¼ˆArgs + trainå‡½æ•°ï¼‰")
            print("  âœ“ è®¾ç½®å°å‚æ•°è¿›è¡Œå¿«é€ŸéªŒè¯")
            print("  âœ“ éªŒè¯äº†è®­ç»ƒæµç¨‹çš„æ‰€æœ‰å…³é”®æ­¥éª¤")
            print("  âœ“ ç¡®è®¤äº†Wrapperä¿®å¤çš„æœ‰æ•ˆæ€§")
            print("\n")
        
        return success
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return False
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

